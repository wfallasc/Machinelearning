{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "freelance-owner",
   "metadata": {},
   "source": [
    "# Google Cloud Example \n",
    "\n",
    "\n",
    "### William Fallas. williamfallas@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-bolivia",
   "metadata": {},
   "source": [
    "#### Spech and translation with  GOOGLE API "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-agenda",
   "metadata": {},
   "source": [
    "The following project shows how to extract audio from video and translate  the same from english to spanish\n",
    "\n",
    "Local Video file: voice-recognition.mp4 \n",
    "\n",
    "Main Steps\n",
    "\n",
    "     -extract audio was format\n",
    "    - Change stereo to mono\n",
    "    - upload wav file to google bucket\n",
    "    - Use the SpeechClient API, long_running_recognize method to get the english transcript\n",
    "    - Use translate_v2 API to translate the transcript from english to spanish\n",
    "    - Transform the spanish transcript to voice with  the texttospeech API \n",
    "    - Save the result in a mp3 file and play\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "above-skating",
   "metadata": {},
   "source": [
    "Necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "healthy-walter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages ---------------------------------------\n",
    "#pip install moviepy\n",
    "#pip install pydub\n",
    "#pip install --upgrade google-cloud-speech\n",
    "#pip install --upgrade google-cloud-storage\n",
    "#pip install google-cloud-translate==2.0.1\n",
    "#!pip install --upgrade google-cloud-texttospeech\n",
    "#pip install pygame#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-snowboard",
   "metadata": {},
   "source": [
    "Set the google credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "played-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"\" # set your credentials here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "chemical-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy\n",
    "from pydub import AudioSegment\n",
    "import io\n",
    "import os\n",
    "import wave\n",
    "from google.cloud import storage\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-mistake",
   "metadata": {},
   "source": [
    "# Sample Video from local drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "featured-transaction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"voice-recognition.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(\"voice-recognition.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-desert",
   "metadata": {},
   "source": [
    "# Get audio from video "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "alternate-buddy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "chunk:   0%|                                                                        | 0/1546 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in speech.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import moviepy.editor\n",
    "video = moviepy.editor.VideoFileClip(\"voice-recognition.mp4\")\n",
    "\n",
    "audio = video.audio\n",
    "\n",
    "audio.write_audiofile(\"speech.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "looking-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def stereo_to_mono(audio_file_name):\n",
    "    sound = AudioSegment.from_wav(audio_file_name)\n",
    "    sound = sound.set_channels(1)\n",
    "    sound.export(audio_file_name, format=\"wav\")\n",
    "\n",
    "\n",
    "def frame_rate_channel(audio_file_name):\n",
    "    with wave.open(audio_file_name, \"rb\") as wave_file:\n",
    "        frame_rate = wave_file.getframerate()\n",
    "        channels = wave_file.getnchannels()\n",
    "        return frame_rate,channels\n",
    "\n",
    "def upload_blob(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "    \n",
    "    \n",
    "def delete_blob(bucket_name, blob_name):\n",
    "    \"\"\"Deletes a blob from the bucket.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "\n",
    "    blob.delete()\n",
    "    \n",
    "    \n",
    "def write_transcripts(transcript_filename,transcript):\n",
    "    f= open( transcript_filename,\"w+\")\n",
    "    f.write(transcript)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ceramic-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"speech.wav\"\n",
    "\n",
    "frame_rate, channels = frame_rate_channel(file_name)\n",
    "    \n",
    "if channels > 1:\n",
    "    stereo_to_mono(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-thursday",
   "metadata": {},
   "source": [
    "Once we have the the audio file, its neccesary upload to google bucket, audio files more than 1 MB must be processed from google bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "naval-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_blob('wfallas_testbucket',\"speech.wav\",\"speech.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-program",
   "metadata": {},
   "source": [
    "Use the long_running_recognize method for long audio files, and wait for 10 seconds for completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "racial-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "gcs_uri = 'gs://' + \"wfallas_testbucket\" + '/' + \"speech.wav\"\n",
    "transcript = ''\n",
    "    \n",
    "client = speech.SpeechClient()\n",
    "audio = dict(uri=gcs_uri)\n",
    "\n",
    "\n",
    "config = speech.RecognitionConfig(\n",
    "        language_code=\"en-US\",\n",
    "        sample_rate_hertz=frame_rate,\n",
    ")\n",
    "\n",
    "\n",
    "    # Detects speech in the audio file\n",
    "operation = client.long_running_recognize(config=config, audio=audio)\n",
    "response = operation.result(timeout=10000)\n",
    "\n",
    "for result in response.results:\n",
    "    transcript += result.alternatives[0].transcript\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-century",
   "metadata": {},
   "source": [
    "#  English transcript from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "shared-pointer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"web accessibility perspectives voice recognition sometimes it's just easier to speak one of the advances of technology is voice recognition whether it's searching the web 19th century architecture send email hard or controlling your navigation app many people with physical disabilities reline voice recognition to use the computer order for that to happen websites and apps need to be property coded cancel voice recognition can help with some other people with temporary limitations to light an injured arm injury over people simply prefer invoice with accessibility essential to some useful. You AI perspectives the more information on voice recognition\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ambient-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_blob(\"wfallas_testbucket\", \"speech.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "matched-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_transcripts(\"EnglishTranscript.txt\",transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-recall",
   "metadata": {},
   "source": [
    "# Translate english transcript to spanish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-denver",
   "metadata": {},
   "source": [
    "Get the spanish translation with translate_v2 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "announced-interview",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def translate_text(target, text):\n",
    "    \n",
    "    translation=\"\"\n",
    "    import six\n",
    "    from google.cloud import translate_v2 as translate\n",
    "\n",
    "    translate_client = translate.Client()\n",
    "\n",
    "    if isinstance(text, six.binary_type):\n",
    "        text = text.decode(\"utf-8\")\n",
    "\n",
    "    # Text can also be a sequence of strings, in which case this method\n",
    "    # will return a sequence of results for each text.\n",
    "    result = translate_client.translate(text, target_language=target)\n",
    "    \n",
    "    translation=result[\"translatedText\"]\n",
    "    return translation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "editorial-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation=\"\"\n",
    "esp=translate_text(\"ES\",transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "material-premiere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'perspectivas de accesibilidad web reconocimiento de voz a veces es más fácil hablar uno de los avances de la tecnología es el reconocimiento de voz, ya sea que busque en la web arquitectura del siglo XIX envíe correo electrónico con fuerza o controle su aplicación de navegación muchas personas con discapacidades físicas reconectan el reconocimiento de voz para usar el orden de la computadora para que para que suceda, los sitios web y las aplicaciones deben tener un código de propiedad, cancelar el reconocimiento de voz puede ayudar a otras personas con limitaciones temporales a encender una lesión en el brazo lesionado en lugar de que las personas simplemente prefieran la factura con accesibilidad esencial para algunos útiles. Sus perspectivas AI cuanta más información sobre el reconocimiento de voz'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-carol",
   "metadata": {},
   "source": [
    "# Transform spanish transcript to audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "academic-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import texttospeech\n",
    "\n",
    "# Instantiates a client\n",
    "client = texttospeech.TextToSpeechClient()\n",
    "\n",
    "# Set the text input to be synthesized\n",
    "synthesis_input = texttospeech.SynthesisInput(text=esp)\n",
    "\n",
    "# Build the voice request, select the language code (\"en-US\") and the ssml\n",
    "# voice gender (\"neutral\")\n",
    "voice = texttospeech.VoiceSelectionParams(\n",
    "    language_code=\"es-ES\", ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL\n",
    ")\n",
    "\n",
    "# Select the type of audio file you want returned\n",
    "audio_config = texttospeech.AudioConfig(\n",
    "    audio_encoding=texttospeech.AudioEncoding.MP3\n",
    ")\n",
    "\n",
    "# Perform the text-to-speech request on the text input with the selected\n",
    "# voice parameters and audio file type\n",
    "response = client.synthesize_speech(\n",
    "    input=synthesis_input, voice=voice, audio_config=audio_config,timeout=10000\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# The response's audio_content is binary.\n",
    "with open(\"output.mp3\", \"wb\") as out:\n",
    "    # Write the response to the output file.\n",
    "    out.write(response.audio_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occasional-matthew",
   "metadata": {},
   "source": [
    "# Play the Final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "western-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pygame import mixer  # Load the popular external library\n",
    "\n",
    "mixer.init()\n",
    "mixer.music.load('output.mp3')\n",
    "mixer.music.play()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
